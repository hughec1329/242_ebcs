\documentclass[11pt]{article}
\usepackage{listings,fancyhdr,hyperref,graphicx,subfig}
\pagestyle{fancy}
\fancyhead{}
\fancyfoot{}
\fancyfoot[C]{-\thepage-}
\fancyfoot[L]{Hugh Crockford}
\fancyfoot[RO]{STA242 - Cow eBCS}
\renewcommand{\footrulewidth}{0.4 pt}
\renewcommand{\headrulewidth}{0 pt}
\hypersetup{colorlinks = true, linkcolor = blue, citecolor = blue}

\title{STA 242 - Final Project - Predicting Cow Body Condition Score from an Image}
\author{\Large{\textsc{Hugh Crockford}}\vspace{0.25in}\\
	Dairy Production Medicine Resident,\\
	Veterinary Medicine Teaching \& Research Center,\\
	University of California, Davis.\\
	18830 Road 112, Tulare, CA. 93274\\
}
\date{\today}
\begin{document}

\begin{center}
	\vspace*{0.3in}
	\LARGE STA 242 - Final Project \\ 
	\Large \emph{Predicting Cow Body Condition Score from an Image} \\ 
	\vspace{0.25in}
	\normalsize \today  // Winter 2013 // Prof. Temple Lang // UC Davis\\ 
	\vspace{0.25in}
	\textsc{Hugh Crockford}\\
	\vspace{0.1in}
	Dairy Production Medicine Resident,\\
	Veterinary Medicine Teaching \& Research Center,\\
	University of California, Davis.\\
\end{center}


	\tableofcontents

	\begin{abstract}
		The application of Image recognition and classification to dairy cow Body Condition Scoring is investigated.
		The Python interface to openCV is used to extract image features, and machine learning/classification techniques within package scikit-learn are used to estimate cow Body condition score.
	\end{abstract}

\newpage
\section{Introduction}
		The US dairy industry produces \$140 Billion in economic output annually, and is California's top Agricultural output. \cite{cmab13}. 
		In the US dairy cattle tend to be intensively managed in large groups, with high standards of feeding and animal husbandry resulting in very high levels of milk output per cow.
		This high intensity production can cause various animal health problems, which will result in weight loss and reduced production.
		Weight loss has been used for some time to identify subclinically diseased animals, however the difficulty in getting an accurate measurement and large day-to-day weight fluctuations due to feeding and watering mean actual weight is a poor predictor of body fat reserves \cite{Roche2004}.
		To overcome this issue various body condition scoring systems have been developed to objectively measure fat cover at various locations, a more sensitive indicator of overall metabolic state \cite{Wildman1982}.
		These scoring systems have proven an important management tool and accurate monitoring will improve animal health, milk production, and reproduction in the modern dairy cow \cite{Buckley2003}.



		Body condition score (BCS) is traditionally been recorded by a trained observer over an 5 or 8 point scale\cite{Bewley2010}, but the time involved to collect and interpret this data has meant herd-wide BCS has rarely been used on commercial dairies.
		For this reason there has been recent interest in the automation of BCS, and various techniques have been developed.


		\begin{figure}[b!]
			\centering
			\includegraphics[scale=0.3]{calf.jpg}
			\caption{North American Holstein dairy heifer from a farm located in the Central Valley, California.}
			\label{fig:}
		\end{figure}
		\newpage

		Bewley used landmarks and angles identified by hand on digital images of cattle to predict BCS using mixture models \cite{Bewley2008}, however the daily tagging of thousands of images in large farm would be unfeasible.
		Hamachi investigated the use of a thermal camera to acquire a contour of the cow's rump and fit a parabola using polygon approximation. 
		The equation and distance from the curve was used to estimate BCS, however low number of cattle and difficulty in automating this workflow limit the use of this technique \cite{Halachmi2008}. 
		Arias used neural networks and automatic image recognition to extract morphologic features from a cow's body based on color differences \cite{Arias2004}. 


		There is clearly scope for an accurate inexpensive computer vision system to classify cow BCS.
		This project will investigate the post-processing of cow images, feature extraction, and machine learning techniques to classify a cow into a body condition class.  


		The techniques developed from this project could also be utilised in the estimated 29.3 Billion beef cows in the United States\cite{USDA2013} and billions of cattle worldwide.

		The Research Objective is to investigate the application of computer vision and machine learning techniques to Body Condition Score dairy cattle.
		The study hypothesis is that these techniques will provide a fast, cost effective technique to BCS a dairy herd and prove a valuable management aid.

\newpage
\section{Methods}
	\subsection{BCS Technique}
		The body condition scoring process takes a combination of subjective measurements of fat cover over anatomical landmarks to decide on a final score.
		The prominence of the hips, tailhead, and spinous processes, as well as the angles between these landmarks are important in making an accurate decision.
		Using image recognition tools we will try to emulate this decision process, by extracting variables that relate to location and size of anatomical landmarks and then assigning the cow a body condition score based on these variables.

	\begin{figure}[h!]
		\centering
		\includegraphics[scale=0.3]{bcseg.jpg}
		\caption{Cow anatomical features used to classify BCS in dairy cows. \cite{Elanco}}
		\label{fig:<+label+>}
	\end{figure}

		Cows are milked at least once a day, sometimes up to 4 times per day so are all present at the milking parlour during this time.
		Automatic image collection on the exit race of the milking parlour using infrared operated cameras or a constant video feed can be coupled with cow identification data from RFID tags to gather multiple images of each cow daily.  

\subsection{Software}
	Opencv is an open source computer recognition library written in C with a BSD licence \cite{opencv_library} and various interfaces.
	I chose to use the python interface as python also has well developed image processing and data analysis/machine learning tools provided by the imtools, PIL, pandas, scikit-learn, scipy and numpy libraries.

	\newpage
\subsection{Image Preprocessing}
	A major problem in any image recognition task is lighting and scale differences between images.
	My proposed image collection procedure was set up in a fairly static environment where I could control lighting and camera position, however cows are fairly reluctant photo models so every image will be different.
	Once collected, the images need to be processed into a form that would allow the feature extraction to take place.


	PIL (python image library) has various tools for importing and manipulating images, and can also access live video streams from a webcam.
	OpenCV2 loads an image as a numpy array with each pixel a tuple of RGB values which facilitates manipulation.


	Many techniques first pass the image through a Gaussian blur to reduce noise/detail and enhance image structure. 
	Increasing the Gaussian blur radius reduces the noise/detail, and improves the performance of edge detecting algorithms such as the 2-d Laplacian filter.
	Converting the image to greyscale is normally the next step as many of the feature extraction algorithms rely on a single measure of intensity for each pixel.

	\begin{figure}[h]
		\centering
		\parbox{5cm}{\includegraphics[width=4cm]{daisy.png}}
		\parbox{5cm}{\includegraphics[width=7cm]{blurcowgrey.jpg}}
		\caption{An example of image preprocessing on our test cow 'Daisy' - original on left, image with Gaussian blur (radius 31 pixels) and converted to greyscale on right.}
	\end{figure}
	\newpage


	Thresholding is another technique to identify objects within an image.
	The image is converted to a binary form by setting a threshold for each pixel, pixels above this level are changed to white, those below to black.
	This technique is commonly employed with earlier generation canny edge detection (see later), which relied on a white object on a black background.
	The color chanel that thresholding is performed upon can also be chosen to isolate objects of a certain color.
	An aspect of image acquisition I will investigate is the manipulation of background color, however due to the nature of the environment (milking barn with cattle faeces) it may be unfeasible to change this.


	While thresholding would improve edge/feature detection, I had a unique problem in that the north American Holstein has a black and white coat.
	If the thresholding/feature recognition algorithms were run on the raw image they would pick up every change in coat color as an edge/contour, but this feature has nothing to do with Body condition score (for further explanation please see discussion).
 	A solution to this problem was proposed by Jianfei \cite{Jianfei2011} and involved examining the grey histogram of a sample of cow pictures.
	The normal values for grey whites and grey blacks of most cows were extracted and a threshold based on the median of these two values computed.
	By mapping all values above this threshold (whites) to their equivalent value below this threshold (blacks), the black and white cow is converted to a black cow, while retaining shadow intensities and details that may assist in classification.


	\begin{figure}[h]
		\centering
		\parbox{6cm}{\includegraphics[width=6cm]{blurcowgrey.jpg}}
		\parbox{6cm}{\includegraphics[width=6cm]{daisyblack.png}}
		\caption{Changing black and white cow to all black using Jianfei's method modified to show region that will be transformed.\cite{Jianfei2011}}
	\end{figure}
\newpage
\subsection{Feature Extraction}
	\subsubsection{Using whole picture}
	I initially looked into facial recognition techniques to see if I could adopt the large amount of work that has been done in this area.


	Eigenfaces were the earliest successful implementation of facial recognition, developed in 1987 by Sirovich and Kirby and implemented in 1991 by Pentland and Turk \cite{Turk1991}.
	The eigenfaces are found by preforming PCA on the covariance matrix of a large number of face pictures, producing an 'average' face or set of standardised facial ingredients to which any face can be matched.
	A serious limitation of eigenfaces is their sensitivity to light and scale/rotation. 
	Since the image is represented as a vector of pixel intensities, if the position of a feature in the image or image lighting, the corresponding pixel intensities will not line up with the eigenfaces and a match will not occur.
	Eigenfaces are innapropriate for cow BCS recognition as the 'eigencows' will get swamped by coat patterns (where the maximum variance occurs) rather than focusing on size and angles of anatomical landmarks.



	Another technique widely used in facial recognition is the detection of Haar-like features, developed by Viola and Jones\cite{viola2004}.
	Haar-like features are found by considering adjacent rectangular areas of an image, summing the pixel intensities and calculating a difference. 
	The size and position of the rectangular detection window is altered and moved consecutively around the image, and differences computed.
	These differences are compared to learned differences stored in a trained Haar Cascade to match features such as eyes, mouth etc.
	Alone each of these features are a poor classifier but when many features of different size and location are combined and passed down a boosting cascade good classification results are achieved very quickly.
	The problem with this approach is the need for a trained Haar cascade - to our knowledge there are no cow Haar cascades available, and the creation of one is both computationally intensive and time consuming.
	
	\begin{figure}[b!]
		\centering
		\includegraphics[scale=0.4]{eigenface.png}
		\caption{An examle of eigenfaces, the 'average' face, or set of standardised features that faces are matched to.}
		\label{fig:<+label+>}
	\end{figure}
\newpage

	The shape of a cow's rump shape changes dramatically from a skinny, angular cow to a round fat cow and another method of predicting BCS is to detect this shape and match to training image.
	Canny developed an edge detection algorithm that examined the first order derivative of the intensity gradient in multiple directions, in order to detect vertical, horizontal, and diagonal edges\cite{Canny1986}.
	The edges that are located are then passed through various threshold filters to remove noise and ensure edges are continuous
	Using this method, an outline of the cow can be generated (cow contour), as well the lines representing important anatomical landmarks such as hooks, pins and tailhead.
	Edges are represented in a binary array, so assuming each image is adjusted for scale and rotation, the location of edges would serve as good predictors of BCS.

	% harris corner detection?

	\begin{figure}[h!]
		\centering
		\parbox{5cm}{\includegraphics[width=5cm]{daisy.png}}
		\parbox{6cm}{\includegraphics[width=8cm]{edges.jpg}}
		\caption{An example of Canny edge detection applied to 'Daisy' image from above (min threshold 5,max 15,kernel size 3) }
		\label{fig:}
	\end{figure}
\newpage


	\subsubsection{Identifying landmarks and calculating distance/angles}

	The second distinct approach to converting cow images to something we can predict BCS with is Feature detection.


	Features are unique areas of an object that can be repeatedly identified across images.
	They are often used when trying to identify an object within a scene, by first extracting invariant features from a training set of images of just the object, and then searching the scene for these features and matching the object.


	The moment is a measure of the shape of set of points and can reveal dimensions, area, and orientation. 
	These descriptors are invariant to scale and rotation, making them an attractive feature for image recognition.
	After contouring via edge detection (see above) moments can be extracted from an image, and the dimensions, angles, and location between these moments can be used to describe cow shape and hence predict BCS.


	
	Scale Invariant Feature Transform (SIFT) is a method for extracting features developed by David Lowe at University of British Columbia\cite{Lowe2004a}.
	The method involves scanning resampled images for maxima and minima of difference of Gaussian functions.
	These locations are mapped and their orientation and dimensions stored as a keypoint which can then be matched to a new image using K Nearest Neighbours or FLANN. 
	A key advantage of this method is the resulting keypoints are invariant to scale, lighting, and orientation changes.
	If keypoints could reliably extracted from important anatomical landmarks and then the location and distance/angle between points calculated BCS could accurately be predicted.
	A serious disadvantage of this method is it is copyrighted.

	\begin{figure}[b!]
		\centering
		\includegraphics[scale=0.22]{SIFT.jpeg}
		\caption{An example of features (colored circles, n=250) extracted  using the SIFT algorithm from a cow image.}
	\end{figure}


\subsection{Training and Classification}
	Once the image has been converted to a series of variables we can train a classifier on a set of human scored cows/images, and then asses it's accuracy on new 'test' cows.
	Our client's milk parlours are processing on average ~200 cows per hour, so a large number of training images could be collected and scored quickly. 
	The availability of vet student labour/'teaching exercises' would also expedite this process.


	Based on personal experience body scoring cattle I anticipate the most accurate prediction of BCS to come from either contouring or feature extraction (with or without variables derived from distance and angles between keypoints)
	After running the images through the preprocessing steps above to generate features, the resulting training dataset can be tried with various classifying techniques, and cross validation and confusion matrices used to assess accuracy.


	Techniques to attempt include: 

	\begin{itemize}
		\item Discriminant Analysis - 
		\item K Nearest Neighbours - flann
		\item Classification and Decision trees (CART) - 
		\item Ensemble methods - A combination of above weak classifiers can be combined and each 
		\item Neural Networks - 
	\end{itemize}

	The accuracy and speed for each combination of feature set and classifier will be assessed.
	Ideally the image processing and classification step would all take place in real time and hence a fast algorithm is required. 
	If, however, it was discovered during testing that a slower algorithm was significantly more accurate then it would be possible to perform the classification in two stages, collection of images from exit lane, and then processing of images by a more powerful server onsite or at our research facility. 

\newpage
\section{Conclusion}
	My brief research into computer vision with python has revealed the capabilities and limitations of various techniques, and I anticipate returning to the VMTRC in the summer to collect images and apply these techniques.\\
%	Provided a reliable, accurate, and cheap system could be developed, there is definitely a market among the large dairy farms in California and Worldwide.

	Future directions for this project to explore include:
	\begin{itemize}
		\item The combination of multiple cameras to get a 3d 'stereo' view of cow. This would allow depth measurements to be computed, giving an indication of the fat fill between landmarks.
			Using our current 2d method we are relying on hollow areas been darker due to shading, and indirectly modelling depth.
			This could also be manipulated by positioning lights around the image capture area to intensify these shadows and hence get a more accurate representation of depth.
		\item Using a Microsoft Kinect sensor would also provide this depth information, and is a cheap and proven method for 3d modelling.
			There are numerous libraries and developer kits available for 3d modelling with the kinect, and the ready availability and low cost make this an attractive option.
		\item The use of single/multiple video monitors. This would eliminate the need for infrared triggers to operate camera, a function could be written to detect when a cow is present in the frame and then select the best image from the video feed. Multiple frames could also be measured and the classification combined to improve prediction accuracy.
		\item Expansion of cow recognition techniques to diagnose lameness in dairy cattle. Lame cows walk slowly with an arched back and short gait, and measurement of spine angle and stride length are predictive of lameness score \cite{Viazzi2013,Pluk2012}. The techniques above could be adapted to measure these variables and predict lameness score.
		\item The combination of above techniques with cow recognition by coat color. This would remove reliance on finicky RFID detectors for cow ID but assumes that each cow has a significantly different coat pattern to allow accurate identification.
	\end{itemize}

	Integration of these techniques with herd management software and automatic drafting gates would provide dairyman with a valuable management tool and improve animal health and production worldwide.

	\newpage

\section{Code}
\lstinputlisting[breaklines=TRUE]{eBCS.py}	

\newpage
\bibliographystyle{unsrt}
\bibliography{ebcs}


\end{document}
